{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Preparing CWT data for deep learning \n",
    "In this notebook, we will describe detailed steps to prepare CWT data to train a deep learning model. CWT is computed from raw time domain data. Time domain data are first segmented and then for each segment, CWT is computed. CWT results are then resized so that they can be fed into a deep learning model.\n",
    "\n",
    "All time domain preprocessing steps including segmenting time domain data for each fault type is detailed in [this notebook](https://github.com/biswajitsahoo1111/cbm_codes_open/blob/master/notebooks/CWRU_time_domain_data_preprocessing.ipynb). After segmenting, the data are saved in a `npz` file named [CWRU_48k_load_1_CNN_data.npz](https://github.com/biswajitsahoo1111/cbm_codes_open/blob/master/notebooks/data/CWRU_48k_load_1_CNN_data.npz). The file is inside data folder. We will use the same file and compute CWT on it."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "First we will import relevant libraries. For wavelet transform we have used [PyWavelets](https://pywavelets.readthedocs.io/en/latest/) package. Image resizing can be done using many libraries. We have used Tensorflow for the same."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pywt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "file = np.load(\"./data/CWRU_48k_load_1_CNN_data.npz\")\n",
    "file.files"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['data', 'labels']"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "raw_data = file[\"data\"]\n",
    "raw_data.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(4600, 32, 32)"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "As the data file was originally intended to be used in a deep learning model, each segment had been resized into size $32 \\times 32$. To compute CWT we have to again resize the matrix like shape into an 1D array. As we are considering a total of 4600 segments, after resizing, our data shape becomes $4600 \\times 1024$.  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "raw_data = raw_data.reshape(-1, 1024)\n",
    "raw_data.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(4600, 1024)"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Following code can be used to compute CWT. The CWT data would be fed into a CNN model that expects input image size to be $32 \\times 32$. Therefore, we resize the output of CWT to a size of $32 \\times 32$. \n",
    "\n",
    "The following code cell might take a long time to execute on a personal computer. Therefore we print a string output after every 100 segments are processed. That would give readers a fair idea as to whether it's worth waiting for the following code cell to finish executing or not. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "wavelet_data = np.repeat(np.nan, repeats = 460 * 10 * 32 * 32).reshape(-1, 32, 32)\n",
    "for i in range(raw_data.shape[0]):\n",
    "    segment = raw_data[i, :]\n",
    "    coefs, _ = pywt.cwt(segment, np.arange(start = 1, stop = 2049, step = 32), \"morl\")\n",
    "    wavelet_data[i, :, :] = tf.reshape(tf.image.resize(coefs.reshape((64, 1024, 1)), (32, 32)), (32, 32))\n",
    "    if (i % 100) == 0 and (i != 0):\n",
    "        print(f\"{i} segments processed.\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "100 segments processed.\n",
      "200 segments processed.\n",
      "300 segments processed.\n",
      "400 segments processed.\n",
      "500 segments processed.\n",
      "600 segments processed.\n",
      "700 segments processed.\n",
      "800 segments processed.\n",
      "900 segments processed.\n",
      "1000 segments processed.\n",
      "1100 segments processed.\n",
      "1200 segments processed.\n",
      "1300 segments processed.\n",
      "1400 segments processed.\n",
      "1500 segments processed.\n",
      "1600 segments processed.\n",
      "1700 segments processed.\n",
      "1800 segments processed.\n",
      "1900 segments processed.\n",
      "2000 segments processed.\n",
      "2100 segments processed.\n",
      "2200 segments processed.\n",
      "2300 segments processed.\n",
      "2400 segments processed.\n",
      "2500 segments processed.\n",
      "2600 segments processed.\n",
      "2700 segments processed.\n",
      "2800 segments processed.\n",
      "2900 segments processed.\n",
      "3000 segments processed.\n",
      "3100 segments processed.\n",
      "3200 segments processed.\n",
      "3300 segments processed.\n",
      "3400 segments processed.\n",
      "3500 segments processed.\n",
      "3600 segments processed.\n",
      "3700 segments processed.\n",
      "3800 segments processed.\n",
      "3900 segments processed.\n",
      "4000 segments processed.\n",
      "4100 segments processed.\n",
      "4200 segments processed.\n",
      "4300 segments processed.\n",
      "4400 segments processed.\n",
      "4500 segments processed.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "For the convenience of readers, we have already saved the wavelet outputs in a `npz` file named [CWRU_48k_load_1_CNN_wavelet_morlet_data.npz](https://github.com/biswajitsahoo1111/cbm_codes_open/blob/master/notebooks/data/CWRU_48k_load_1_CNN_wavelet_morlet_data.npz). That file is saved in the data folder. To convince ourselves that the data available online is the same as obtained in the last code cell, we will compare the outputs of previous cell with the online saved data."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "online_file = np.load(\"./data/CWRU_48k_load_1_CNN_wavelet_morlet_data.npz\")\n",
    "online_file.files"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['data', 'labels']"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "online_wavelet_data = online_file[\"data\"]\n",
    "online_wavelet_data.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(4600, 32, 32)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Checking whether both the data are identical or not."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "4600 * 1024"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "4710400"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "np.sum(np.isclose(wavelet_data, online_wavelet_data))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "4710400"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "As we can see both the data are indeed identical. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save wavelet data\n",
    "We can save both data and labels in a single `npz` file. We have commented the line that actually saves data as already have saved the file in `data` folder. Readers who wish to save it again can do so by uncommenting the line."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "fault_types = ['Ball_007', 'Ball_014', 'Ball_021', 'IR_007', 'IR_014', 'IR_021', 'OR_007','OR_014', 'OR_021', 'Normal']\n",
    "labels = np.repeat(fault_types, 460)\n",
    "\n",
    "# np.savez('CWRU_48k_load_1_CNN_wavelet_morlet_data', data = wavelet_data, labels = labels)   # Save wavelet data"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('tf_241_gpu': conda)"
  },
  "interpreter": {
   "hash": "22fb862aab768b4910ec0129995242e01af1a70f0bfcd1a8911b558fd509f5b3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}